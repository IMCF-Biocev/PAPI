{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb5add9",
   "metadata": {},
   "source": [
    "## The full Image Analysis Workflow\n",
    "\n",
    "In this notebook, we will build a complete, end-to-end image analysis pipeline. We'll start with a complex, multi-channel image, learn how to handle and process it, extract quantitative data, and finally, automate the entire workflow to run on a batch of images.\n",
    "\n",
    "Workflow:\n",
    "1. Image Handling: Loading multi-dimensional data, inspecting it, and slicing out regions of interest.\n",
    "2. Processing workflow:\n",
    "    - Pre-processing: Cleaning up image noise with filters.\n",
    "    - Segmentation & post-processing: Finding objects with thresholding and cleaning them with morphological operations.\n",
    "4. Measurement & Analysis: Turning segmented objects into a table of data for plotting and statistical testing.\n",
    "5. Automation: Automationg processing and scaling the analysis from one image to many."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22911561",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "### Lesson 1: Load image data and metadata\n",
    "\n",
    "When working with microscopy or scientific images, the first step is to **load the image** and explore its **metadata**. Understanding the file type and metadata is crucial for processing, analyzing, and storing images correctly.\n",
    "\n",
    "**Common Bioimage File Types**\n",
    "\n",
    "In microscopy and scientific imaging, images can come in a wide range of **file formats**, each with different capabilities. \n",
    "\n",
    "\n",
    "| File Type      | Typical Use Case / Notes                                                      | Bit Depth |\n",
    "|-------------|-------------------------------------------------------------------------------|--------------|\n",
    "| **TIFF / TIF** | Standard in microscopy; supports multi-page images (z-stacks, time-lapse)   | 8–32      |\n",
    "| **OME-TIFF (.ome.tif)** | Open Microscopy Environment format; stores multi-channel, multi-dimensional images with metadata | 8–32      |\n",
    "| **JPEG / JPG** | Compressed (lossy) images, often for visualization rather than analysis               | 8         |\n",
    "| **PNG**        | Lossless 8-bit/16-bit images; supports transparency                          | 8–16      |\n",
    "| **Zarr (.zarr)**| Chunked, compressed storage for very large multidimensional datasets         | 8–32      |\n",
    "| **Proprietary formats** (e.g., `.czi` Zeiss, `.lif` Leica, `.nd2` Nikon) | Often contain full acquisition metadata but might require specialized readers | Varies    |\n",
    "\n",
    "**Example Generic Reading Libraries**\n",
    "- `skimage.io`, `imageio`,  `tifffile`, `PIL.Image`, `AICSImageIO.AICSImage` x `BioIO`\n",
    "\n",
    "**Example Specialized format reading libraries**\n",
    "-  `czifile`, `readlif`\n",
    "\n",
    "**Key Points**\n",
    "\n",
    "- **Images are arrays**: Whatever the format, libraries usually convert data to a **NumPy array** (or Dask array for Zarr).  \n",
    "- **Metadata** are additional information: Pixel size, physical units, channel names, acquisition settings... — **not all libraries can read metadata**.  \n",
    "- **Large datasets**: Zarr or HDF5 formats are useful when images don’t fit in memory.  \n",
    "- **Proprietary formats**: Often require **specialized libraries**; trying to open with a generic library may fail or lose metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aac8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, first we need to import packages\n",
    "import imageio.v3 as iio\n",
    "import numpy as np\n",
    "\n",
    "# Read image metadata (if available)\n",
    "\n",
    "# First define a path to image\n",
    "image_location = r'../data/mitosis.tif'\n",
    "\n",
    "metadata = iio.immeta(image_location)\n",
    "print(metadata)\n",
    "\n",
    "# for key,value in metadata.items():\n",
    "#     print(f'{key}: \\t {value}') # \\t is for tab; \\n for newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c68190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note about file paths\n",
    "\n",
    "# Absolute path: full address on the filesystem\n",
    "absolute_path = \"C:/Users/Username/Documents/demo_cells_image.tif\"\n",
    "print(\"Absolute path:\", absolute_path)\n",
    "\n",
    "# Relative path: relative to where your Python script / notebook is running\n",
    "# Special relative markers:\n",
    "#   .  = current directory\n",
    "#   .. = parent directory (one level up)\n",
    "relative_path = \"../data/demo_cells_image.tif\"\n",
    "print(\"Relative path:\", relative_path)\n",
    "\n",
    "# Raw string (r\"...\"): avoids interpreting backslashes as escape sequences\n",
    "raw_path = r\"C:\\Users\\Username\\Documents\\demo_cells_image.tif\"\n",
    "print(\"Raw string path:\", raw_path)\n",
    "\n",
    "# We will discuss more about dedicated libraries during batch Lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af5d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image data\n",
    "image_stack = iio.imread(image_location)\n",
    "\n",
    "# Inspect image dimensions\n",
    "print(\"The full data is a NumPy array with the following properties:\")\n",
    "print(f\"Data type: {image_stack.dtype}\")\n",
    "print(f\"Dimensions: {image_stack.ndim}\")\n",
    "print(f\"Shape: {image_stack.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ffa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single slice\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "single_slice_ch1 = image_stack[0,2,0,:,:]\n",
    "single_slice_ch2 = image_stack[0,2,1,:,:]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow(single_slice_ch1, cmap='gray')\n",
    "ax[0].set_title(\"Channel 0\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(single_slice_ch2, cmap='gray')\n",
    "ax[1].set_title(\"Channel 1\")\n",
    "ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c34a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browse a stack\n",
    "import stackview # Interactive image stack viewing in jupyter notebooks\n",
    "print(stackview.__version__)\n",
    "\n",
    "stackview.slice(image_stack) # we need version > 0.10 to use this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd9abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be customized a bit\n",
    "\n",
    "channels = [image_stack[:,:,0,:,:], image_stack[:,:,1,:,:]]\n",
    "colormaps = [\"pure_green\", \"pure_magenta\"] \n",
    "\n",
    "stackview.switch(images=channels, colormap=colormaps, toggleable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c9653e",
   "metadata": {},
   "source": [
    "#### Inspect intensity data\n",
    "\n",
    "It is often useful to explore the distribution of pixel intensities before performing any further analysis. \n",
    "\n",
    "This can helps us identify:\n",
    "- Background vs. foreground signal\n",
    "- Differences between channels\n",
    "- Outliers or artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a15d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stackview.insight() function provides a quick overview of the intensity distributions\n",
    "stackview.insight(image_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485f128d",
   "metadata": {},
   "source": [
    "If we want more control over plotting or calculating statistics, we can flatten the multi-dimensional arrays of each channel using function `ravel()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb01383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram per channel\n",
    "\n",
    "ch0_data = image_stack[:, :, 0, :, :].ravel()   # Flatten everything \n",
    "ch1_data = image_stack[:, :, 1, :, :].ravel()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(ch0_data, bins=100, alpha=0.5, label=\"Channel 0\")\n",
    "plt.hist(ch1_data, bins=100, alpha=0.5, label=\"Channel 1\")\n",
    "#plt.xlim(1000, 10000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Channel 0: min =\", ch0_data.min(), \", max =\", ch0_data.max(),\n",
    "      \", mean =\", ch0_data.mean(), \", std =\", ch0_data.std())\n",
    "\n",
    "print(\"Channel 1: min =\", ch1_data.min(), \", max =\", ch1_data.max(),\n",
    "      \", mean =\", ch1_data.mean(), \", std =\", ch1_data.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452dfc52",
   "metadata": {},
   "source": [
    "#### Image transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a798567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets read a new image\n",
    "\n",
    "image = iio.imread('../data/nuclei_stack1.tif')\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "stackview.slice(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f259e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image cropping\n",
    "# Can be done simply by slicing array\n",
    "\n",
    "crop_area1 = image[:,520:,420:]\n",
    "print(crop_area1.shape)\n",
    "\n",
    "stackview.slice(crop_area1, zoom_factor=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0d584",
   "metadata": {},
   "source": [
    "#### Projections\n",
    "\n",
    "Collapses a stack along an axis to reduce dimensions.\n",
    "\n",
    "Common projections include:\n",
    "- **Maximum intensity projection (MIP)**: For each pixel, take the highest intensity across slices. Useful for highlighting bright structures like nuclei or fluorescently labeled organelles.\n",
    "- **Average (mean) projection**: Computes the mean intensity at each pixel. Smooths noise and shows overall signal distribution.\n",
    "- **Sum projection**: Sums intensities across slices; can help quantify total signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2498c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections\n",
    "# We can collapse one axis (e.g., z-axis in a 3D stack) using functions (sum, mean, max, min, ...)\n",
    "\n",
    "# Examples - for convenience we will put it to a dictionary\n",
    "projections = {\n",
    "    \"Max\": np.max(image, axis=0),\n",
    "    \"Mean\": np.mean(image, axis=0),\n",
    "    \"Sum\": np.sum(image, axis=0),\n",
    "    \"Min\": np.min(image, axis=0),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, len(projections), figsize=(20, 5))\n",
    "for index, ax in enumerate(axes):\n",
    "    ax.imshow(list(projections.values())[index], cmap='gray')\n",
    "    ax.set_title(f\"{list(projections.keys())[index]} Projection\")\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbcfd37",
   "metadata": {},
   "source": [
    "#### Geometric transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ba478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation module\n",
    "from skimage import transform\n",
    "\n",
    "# Rotation\n",
    "max_proj = projections['Max']\n",
    "rotated_90 = np.rot90(max_proj, k=1) # either use numpy for 90degrees multiples\n",
    "rotated_45 = transform.rotate(max_proj, angle=45, resize=False) # or skimage transform functions (allows interpolation)\n",
    "\n",
    "# Rescale\n",
    "down_sized = transform.rescale(max_proj, scale=0.5, anti_aliasing=True)\n",
    "\n",
    "images_list = [max_proj, rotated_90, rotated_45, down_sized]\n",
    "titles_list = ['Untransformed', 'Rotated 90', 'Rotated 45', 'Down-scaled 2x']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for index, ax in enumerate(axes):\n",
    "    ax.imshow(images_list[index], cmap='gray')\n",
    "    ax.set_title(f'{titles_list[index]}, {images_list[index].shape}')\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0ca5f",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Lesson 2: Processing workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb36e0d",
   "metadata": {},
   "source": [
    "#### Pre-processing\n",
    "\n",
    "**Image Filtering**\n",
    "\n",
    "A filter is a mathematical operation applied to an image to modify or extract information from it. Filters are used to:\n",
    "\n",
    "- Reduce noise (smoothing) - (Gaussian, Median)\n",
    "- Highlight edges or boundaries (edge detection) - (Sobel)\n",
    "- Enhance contrast or features\n",
    "- Extract specific patterns or textures\n",
    "\n",
    "\n",
    "Most filters are implemented using a **kernel**.\n",
    "\n",
    "- A kernel is a small array of numbers.\n",
    "- The kernel is “slid” across the image (convolution), computing a weighted sum of the neighboring pixel values for each position.\n",
    "- The result is a new image where each pixel represents the combined effect of the kernel on its neighborhood.\n",
    "Some filters are used to smooth or denoise images.\n",
    "\n",
    "Kernel size affects the scale of the effect: small kernels for fine details, large kernels for broader effects.\n",
    "\n",
    "Example: A 3×3 Gaussian kernel for smoothing:\n",
    "\n",
    "$$\n",
    "K = \\frac{1}{16}\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 1 \\\\\n",
    "2 & 4 & 2 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b5ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will define a convenient helper function for plotting before-after images\n",
    "\n",
    "def plot_comparison(original, modified, modified_title=None):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "    ax1.imshow(original, cmap='gray'); ax1.set_title('Original')\n",
    "    ax2.imshow(modified, cmap='gray'); ax2.set_title(modified_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "from skimage import filters\n",
    "\n",
    "image_frame = image[0, :, :]\n",
    "\n",
    "# Apply a Gaussian filter to nuclei. \n",
    "# 'sigma' controls the amount of smoothing\n",
    "blurred_image = filters.gaussian(image_frame, sigma=2.0)\n",
    "\n",
    "plot_comparison(image_frame, blurred_image, \"After Gaussian Blur\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rank filters\n",
    "\n",
    "# Apply a Median filter to nuclei. \n",
    "median_filtered_image = filters.rank.median(image_frame)\n",
    "\n",
    "plot_comparison(image_frame, median_filtered_image, \"Median filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2872d47f",
   "metadata": {},
   "source": [
    "#### Segmentation\n",
    "\n",
    "Segmentation separates the image into meaningful regions (e.g., cells, nuclei, mitochondria). \n",
    "\n",
    "Examples:\n",
    "- **Thresholding**: Converts grayscale images to binary masks. \n",
    "    - Pixels above a threshold are considered “foreground.” \n",
    "    - Thresholds can be manually chosen or computed automatically (e.g., Otsu’s method).\n",
    "- **Edge detection**: Finds boundaries of objects based on intensity gradients.\n",
    "- **Watershed**: Separates touching objects using topographic interpretation of intensity as landscapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd02da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation \n",
    "\n",
    "# Use Otsu's method to find the optimal threshold value.\n",
    "otsu_threshold = filters.threshold_otsu(image_frame)\n",
    "print(f\"The automatically determined Otsu threshold is: {otsu_threshold}\")\n",
    "\n",
    "# Apply the threshold to create the binary mask.\n",
    "mask = image_frame > otsu_threshold\n",
    "\n",
    "plot_comparison(image_frame, mask, \"Otsu's Threshold Applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871825e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use filtered image as input \n",
    "\n",
    "otsu_threshold = filters.threshold_otsu(blurred_image)\n",
    "mask = blurred_image > otsu_threshold\n",
    "\n",
    "plot_comparison(blurred_image, mask, \"Otsu's Threshold Applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23c8d6e",
   "metadata": {},
   "source": [
    "#### Post-processing\n",
    "\n",
    "Morphological Operations on Binary Masks:\n",
    "- *Erosion*: Shrinks objects\n",
    "- *Dilation*: Expands objects.\n",
    "- *Opening* (erosion → dilation)\n",
    "- *Closing* (dilation → erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eba86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological Operations\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import morphology\n",
    "\n",
    "mask_filled = ndi.binary_fill_holes(mask) # Fill holes \n",
    "mask_opened = morphology.opening(mask_filled, morphology.disk(3)) #opening \n",
    "mask_cleaned = morphology.remove_small_objects(mask_opened, min_size=100) # Remove small objects (noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c64b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(mask, mask_cleaned, 'cleaned mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d806b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connected components labeling ~ instance segmentation\n",
    "from skimage import measure\n",
    "\n",
    "labels = measure.label(mask_cleaned)\n",
    "\n",
    "print(f\"Found {labels.max()} objects after cleaning and labeling.\")\n",
    "\n",
    "plot_comparison(mask_cleaned, labels, 'Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watershed\n",
    "from skimage import segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "distance = ndi.distance_transform_edt(mask_cleaned)\n",
    "coords = peak_local_max(distance, min_distance=20, labels=mask_cleaned)\n",
    "\n",
    "markers = np.zeros_like(distance, dtype=int)\n",
    "for i in range(len(coords)):\n",
    "    markers[coords[i, 0], coords[i, 1]] = i + 1\n",
    "\n",
    "# Watershed\n",
    "labels_watershed = segmentation.watershed(-distance, markers, mask=mask_cleaned)\n",
    "\n",
    "plot_comparison(labels, labels_watershed, 'Watershed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = morphology.dilation(markers)>0\n",
    "steps = [mask_cleaned, distance, markers, labels_watershed]\n",
    "processing_stack = np.stack(steps, axis = 0)\n",
    "\n",
    "stackview.slice(processing_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d5a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as overlay\n",
    "# multiple options (napari, matplotlib with alpha, sepcialized packages - label2rgb or stackview)\n",
    "stackview.blend(image_frame, labels_watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214e41f",
   "metadata": {},
   "source": [
    "### Summary of our Workflow\n",
    "We've just completed a full, basic image processing pipeline:\n",
    "1. **Loaded** an image.\n",
    "2. **Pre-processed** it by applying a Gaussian blur to reduce noise.\n",
    "3. **Segmented** the nuclei class from the background by applying an automatic Otsu threshold.\n",
    "4. **Refined** the resulting mask by using post-processing steps such as morphological operations.\n",
    "5. Distinguised individual objects in binary mask with **connected components labeling**\n",
    "\n",
    "Now is time for exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2fd93",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** ---\n",
    "\n",
    "Perform the following steps to build a workflow to process an image.\n",
    "\n",
    "1. Load the image from the assigned `image_path` variable.\n",
    "2. Inspect it's properties.\n",
    "    - find out the dimensions, size and data type of pixel values\n",
    "    - optionally, inspect metadata if it exists\n",
    "3. Show image in notebook (stackview or matplotlib)\n",
    "4. Extract the mitochondrial channel (2nd)\n",
    "5. The image is a bit noisy with high background. \n",
    "    - Apply a Gaussian filter - try different sigma values.\n",
    "    - optionally, remove background using skimage.restoration.rolling_ball - \n",
    "        *Hint:* you need to first import it.\n",
    "        The output is a background image, not background subtracted image.\n",
    "6. Plot histogram of blurred/corrected image.\n",
    "7. Compute automatic thresholds using Otsu and Mean methods.\n",
    "8. Segment the image using both threshold methods and choose the best one.\n",
    "    - Use `plot_comparison()` to show the two binary masks side by side.\n",
    "9. Improve segmentation (optional)\n",
    "    - Apply morphological operations to clean the mask (skimage.morphology)\n",
    "10. Perform instance segmentation to get labels\n",
    "11. Visualize the results\n",
    "    - Show the labeled objects over the original mitochondrial channel (e.g., using stackview.blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../data/BPAE.tif'\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e6239",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "from skimage import restoration\n",
    "\n",
    "# 1. Load image\n",
    "img = iio.imread(image_path)\n",
    "\n",
    "# 2. Inspect properties\n",
    "print(img.shape, img.size, img.dtype)\n",
    "\n",
    "# 3. Visualize\n",
    "stackview.slice(img)\n",
    "plt.show()\n",
    "\n",
    "# 4. Extract mitochondrial channel\n",
    "mito = img[1,:,:]\n",
    "\n",
    "# 5. Denoise / background removal\n",
    "i = filters.gaussian(mito, sigma=2)\n",
    "i = i - restoration.rolling_ball(i, radius=15)\n",
    "i = i.astype(np.uint16)\n",
    "\n",
    "plt.imshow(i, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# 6. Histogram\n",
    "plt.hist(i.ravel(), bins=50)\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "# 7. Automatic thresholds\n",
    "otsu_thr = filters.threshold_otsu(i)\n",
    "mean_thr = filters.threshold_mean(i)\n",
    "print(otsu_thr, mean_thr)\n",
    "\n",
    "# 8. Segment\n",
    "mask_otsu = i > otsu_thr\n",
    "mask_mean = i > mean_thr\n",
    "\n",
    "plot_comparison(mask_otsu, mask_mean)\n",
    "\n",
    "# 9. Morphological cleaning (optional)\n",
    "\n",
    "# 10. Instance segmentation\n",
    "labels = morphology.label(mask_otsu)\n",
    "\n",
    "# 11. Visualization\n",
    "stackview.blend(img, labels)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bb0487",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "#### Operations between masks\n",
    "\n",
    "In image analysis, it is often useful to combine or compare different binary masks to extract specific regions of interest. Masks as boolean arrays (True for foreground, False for background), can be processed with logical operations to create new masks.\n",
    "\n",
    "Common operations:\n",
    "- *Inversion - NOT (`~`)* – flips all boolean values:\n",
    "    ```python\n",
    "    inverted_mask = ~mask\n",
    "    ```\n",
    "- *Intersection (`&`)* – keeps only pixels present in both masks:\n",
    "    ```python\n",
    "    overlap_mask = mask1 & mask2\n",
    "    ```\n",
    "- *Union (`|`)* – includes all pixels present in either mask:\n",
    "    ```python\n",
    "    combined_mask = mask1 | mask2\n",
    "    ```\n",
    "- *Difference / Subtraction (`& ~`)* – removes pixels of one mask from another:\n",
    "    ```python\n",
    "    cytoplasm_mask = cell_mask & ~nuclei_mask\n",
    "    ```\n",
    "- *Exclusive OR (`^`)* – pixels present in one mask or the other, but not both:\n",
    "    ```python\n",
    "    xor_mask = mask1 ^ mask2\n",
    "    ```\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "* Make sure all masks have the same shape before performing operations.\n",
    "* Use parentheses to clarify operations with multiple masks:\n",
    "    ```python\n",
    "    final_mask = (mask1 | mask2) & ~mask3\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23546bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tilde operator\n",
    "mask = np.array([True, False, True])\n",
    "inverted_mask = ~mask\n",
    "inverted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use case\n",
    "\n",
    "cell_mask = iio.imread('../data/BPAE_actin_mask.tif')\n",
    "background_mask = ~cell_mask\n",
    "\n",
    "plot_comparison(cell_mask, background_mask, 'background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389afd44",
   "metadata": {},
   "source": [
    "**Example Use Case:**\n",
    "\n",
    "You have a cell_mask, a nuclei_mask, and a mitochondria_mask. If you want to extract the cytoplasm region, you can subtract the nucleus and mitochondria regions from the cell mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b265611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read segmentation of mitochondria\n",
    "mito_labels = iio.imread('../data/BPAE_mito_lbl.tif')\n",
    "mito_binary = (mito_labels > 1) # convert to boolean array\n",
    "\n",
    "plot_comparison(mito_labels, mito_binary, 'binary')\n",
    "\n",
    "# Read nuclei masks\n",
    "nuclei_mask = iio.imread('../data/BPAE_nuclei_mask.tif')\n",
    "\n",
    "cytoplasm_mask = cell_mask & ~nuclei_mask & ~mito_binary\n",
    "\n",
    "plot_comparison(cell_mask, cytoplasm_mask, '\"cytoplasm\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5705c",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Lesson 3: Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79a2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements\n",
    " \n",
    "# We specify which properties we want to measure for each object.\n",
    "properties_to_measure = ('label', 'area', 'mean_intensity', 'perimeter', 'eccentricity')\n",
    "\n",
    "# regionprops_table uses our `labels` image and the original `nuclei_image`\n",
    "props_dict = measure.regionprops_table(\n",
    "    labels_watershed,\n",
    "    intensity_image=image_frame,\n",
    "    properties=properties_to_measure\n",
    ")\n",
    "\n",
    "props_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary of results into a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "image_df = pd.DataFrame(props_dict)\n",
    "\n",
    "image_df.head(5) # show first 5 rows of a table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a230bf",
   "metadata": {},
   "source": [
    "#### DataFrames (Pandas package)\n",
    "\n",
    "Pandas is a powerful Python library used for data manipulation and analysis, particularly useful for dealing with structured data like tables.\n",
    "\n",
    "DataFrame is a two-dimensional data structure similar to a spreadsheet (table).\n",
    "\n",
    "We typically import pandas like this:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from a dictionary of lists\n",
    "import pandas as pd\n",
    "\n",
    "measurement_data = {\n",
    "    'cell_id': [1, 2, 3, 4],\n",
    "    'area': [150, 230, 95, 180],\n",
    "    'intensity': [88.5, 95.2, 101.0, 89.7]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(measurement_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096893c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily get statistics from our data with .describe()\n",
    "print(\"\\n--- Summary Statistics ---\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b1cdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can extract dataframes columns data with\n",
    "\n",
    "area_column = df['area']\n",
    "print(area_column)\n",
    "\n",
    "print()\n",
    "\n",
    "# or \n",
    "area_values = df['area'].values\n",
    "print(area_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can filter data based on conditions\n",
    "# This creates a new DataFrame containing only the cells with an area less than 200.\n",
    "filtered_df = df[df['area'] < 200]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e52073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or more complex filters\n",
    "\n",
    "filtered_df2 = df[(df['area'] < 200) & (df['area'] > 150)]\n",
    "filtered_df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can sort dataframes by one or more columns.\n",
    "# ascending=True/False controls ascending/descending order\n",
    "\n",
    "sorted_df = df.sort_values(by='intensity', ascending=False)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea64f7",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** ---\n",
    "\n",
    "You have experimental data in a dictionary. Your task is to analyze it with Pandas.\n",
    "1. Create a **Pandas DataFrame** from the given data dictionary.\n",
    "2. Filter the DataFrame to find all rows where the **Treatment** was `'Drug_A'`.\n",
    "3. From that filtered data, compute the **average Score** for Drug A.\n",
    "4. Using the entire DataFrame, find out **which treatments were effective**.  \n",
    "   *Hint: use the equality operator `==` and consider grouping by Treatment.*\n",
    "5. Display the **3 rows with the highest Score**.  \n",
    "   *Hint: use `.sort_values('Score', ascending=False).head(3)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59366ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cd\n",
    "data = {'Animal_id': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
    "        'Treatment': ['Drug_A', 'Drug_B', 'Placebo', 'Drug_A', 'Drug_B', 'Placebo', 'Drug_A', 'Drug_B', 'Drug_A', 'Drug_B'],\n",
    "        'Result': ['Effective', 'Not Effective', 'Not Effective', 'Effective', 'Effective', 'Not Effective', 'Effective', 'Effective', 'Effective', 'Not Effective'],\n",
    "        'Score': [50.3, 3.5, 10.1, 17.0, 93.3, 1.5, 99.9, 73.7, 69.2, 0.5]}\n",
    "\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810da2a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "# 1. Create DataFrame from dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 2. Filter rows where Treatment is 'Drug_A'\n",
    "drug_a_df = df[df['Treatment'] == 'Drug_A']\n",
    "print(\"Rows with Drug_A treatment:\")\n",
    "print(drug_a_df)\n",
    "\n",
    "# 3. Average Score for Drug_A\n",
    "avg_score_drug_a = drug_a_df['Score'].mean()\n",
    "print(\"\\nAverage Score for Drug_A:\", avg_score_drug_a)\n",
    "\n",
    "# 4. Which treatments were effective?\n",
    "effective_treatments = df[df['Result'] == 'Effective']['Treatment'].unique()\n",
    "print(\"\\nTreatments with at least one effective result:\", effective_treatments)\n",
    "\n",
    "# 5. Display 3 rows with the highest 'Score'\n",
    "top3_scores = df.sort_values('Score', ascending=False).head(3)\n",
    "print(\"\\nTop 3 rows by Score:\")\n",
    "print(top3_scores)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a7f948",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251a0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements analysis\n",
    "\n",
    "# we can save our DataFrame \n",
    "image_df.to_csv('first_measurements.csv', index=False)\n",
    "\n",
    "# read measurement from file\n",
    "loaded_df = pd.read_csv('first_measurements.csv') # check other file formats\n",
    "loaded_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3356cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes are convenient for plotting\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.hist(loaded_df['area'], bins=10)\n",
    "plt.title('histogram')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(loaded_df['area'], loaded_df['mean_intensity'])\n",
    "plt.title('scatterplot')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Mean intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf19bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation (multiple tables)\n",
    "\n",
    "df_image1 = pd.read_csv(\"../data/cells_control.csv\")\n",
    "df_image2 = pd.read_csv(\"../data/cells_diseased.csv\")\n",
    "df_image3 = pd.read_csv(\"../data/cells_conditioned.csv\")\n",
    "\n",
    "# merge dataframes\n",
    "combined_df = pd.concat([df_image1, df_image2, df_image3], ignore_index=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a812a8a",
   "metadata": {},
   "source": [
    "##### DataFrame data types\n",
    "\n",
    "Pandas has a few handy tools to quickly check the dtype (data type) of your columns:\n",
    "\n",
    "    ```python\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(df.info())\n",
    "    ```\n",
    "\n",
    "Data types can be:\n",
    "- int64, float64 → numeric columns\n",
    "- object → usually strings (categories, text)\n",
    "- category → categorical data (memory-efficient, useful for grouping)\n",
    "\n",
    "You can convert string/object columns to categorical with method: `.astype(\"category\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bf8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[\"Group\"] = combined_df[\"Group\"].astype(\"category\")\n",
    "combined_df[\"State\"] = combined_df[\"State\"].astype(\"category\")\n",
    "\n",
    "print(combined_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a506f2",
   "metadata": {},
   "source": [
    "##### Group-level statistics\n",
    "\n",
    "This is especially useful when your dataset contains categorical variables (like experimental groups, treatments, or conditions) and numeric measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7c3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe method is applied on entire dataframe without disciminating categories\n",
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to extract statistics per group, we can use methods group_by() and agg() (aggregate)\n",
    "\n",
    "# agg works only on numerical columns, we need to remove all other types first\n",
    "reduced_df = combined_df.drop(\"State\", axis=1) \n",
    "\n",
    "summary_per_group = reduced_df.groupby('Group').agg([\"count\", \"mean\", \"std\"]) \n",
    "summary_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bc8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can address multiple factors\n",
    "summary_per_group_and_state = combined_df.groupby(['Group','State'], observed=False).agg([\"count\", \"mean\", \"std\"]) \n",
    "summary_per_group_and_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc4555",
   "metadata": {},
   "source": [
    "##### Visualizing group differences with Seaborn\n",
    "\n",
    "The **Seaborn** library builds on Matplotlib but provides higher-level plotting functions tailored for statistical data.\n",
    "\n",
    "A particularly useful feature is the `hue` argument, which colors data points by group/category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0227b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn \n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(\n",
    "    data=combined_df, \n",
    "    x=\"Group\", \n",
    "    y=\"Mean_Intensity\", \n",
    "    hue=\"Group\", \n",
    "    palette=\"Set2\"\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f956db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some seaborn plots also allow discrimination of multiple factors\n",
    "  \n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(\n",
    "    data=combined_df, \n",
    "    x=\"Area\", y=\"Circularity\", \n",
    "    hue=\"Group\", style='State'\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a86049",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "\n",
    "Visualization gives intuition, but we often want statistical confirmation. Using `scipy.stats`, we can perform a t-test to see if group means differ significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6212f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis testing\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# the following is combination of filtering dataframe and extracting column Mean_Intensity\n",
    "controls = combined_df[combined_df['Group']=='Control']['Mean_Intensity']\n",
    "diseased = combined_df[combined_df['Group']=='Diseased']['Mean_Intensity']\n",
    "\n",
    "# the t-test takes two lists/arrays to compare mean\n",
    "# by default the ttest_ind() performs two-sided t-test and assumes independent samples\n",
    "t_stat, p_value = ttest_ind(controls, diseased)\n",
    "\n",
    "print(f\"\\nT-test p-value for comparing areas: {p_value:.9f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ca48a6",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** ---\n",
    "\n",
    "\n",
    "On `combined_df` from previous exercises perform the following:\n",
    "\n",
    "1. Compute mean and standard deviation of all numerical columns per factor **State**. \n",
    "    - Which cells have the largest average area?\n",
    "2. Make a boxplot comparing **Area** across categories of **State**.\n",
    "4. Add a swarmplot (`sns.swarmplot`) on top to see individual datapoints.\n",
    "5. Perform a t-test comparing \"Circularity\" between Control and Diseased.\n",
    "6. Perform a t-test comparing \"Mean_Intensity\" between Starved Pre-conditioned and Unstarved Pre-conditioned.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eced295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37b2422",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "# Compute mean and std per State\n",
    "r_df = combined_df.drop('Group', axis=1)\n",
    "summary_state = r_df.groupby(\"State\", observed=False).agg([\"mean\", \"std\"]).round(2) # optional rounding\n",
    "print(summary_state)\n",
    "\n",
    "# Boxplot with swarmplot for Area per State\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(data=combined_df, x=\"State\", y=\"Area\", palette=\"Set2\", hue='State')\n",
    "sns.swarmplot(data=combined_df, x=\"State\", y=\"Area\", color='black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# T-test Circularity: Control vs Diseased\n",
    "controls = combined_df[combined_df[\"Group\"] == \"Control\"][\"Circularity\"]\n",
    "diseased = combined_df[combined_df[\"Group\"] == \"Diseased\"][\"Circularity\"]\n",
    "t_stat, p_value = ttest_ind(controls, diseased)\n",
    "print(f\"T-test Circularity (Control vs Diseased): p = {p_value:.4f}\")\n",
    "\n",
    "# T-test Mean_Intensity: Starved vs Unstarved Pre-conditioned\n",
    "pre_starved = combined_df[\n",
    "    (combined_df[\"Group\"] == \"Pre-conditioned\") & (combined_df[\"State\"] == \"Starved\")\n",
    "][\"Mean_Intensity\"]\n",
    "pre_unstarved = combined_df[\n",
    "    (combined_df[\"Group\"] == \"Pre-conditioned\") & (combined_df[\"State\"] == \"Unstarved\")\n",
    "][\"Mean_Intensity\"]\n",
    "t_stat, p_value = ttest_ind(pre_starved, pre_unstarved)\n",
    "print(f\"T-test Mean_Intensity (Starved vs Unstarved, Pre-conditioned): p = {p_value:.4f}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3d4fd",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Lesson 4: Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac2b4d",
   "metadata": {},
   "source": [
    "In the previous Lesson, we practiced designing and tuning a full image-processing workflow:\n",
    "- We loaded and visualized microscopy images.\n",
    "- We adjusted individual processing steps such as filtering, thresholding, and segmentation.\n",
    "- We extracted quantitative measurements (e.g., area, intensity, circularity).\n",
    "- Finally, we analyzed those measurements using **Pandas**, **Seaborn**, and **scipy** packages.\n",
    "\n",
    "That workflow worked — but it was **manual**.  \n",
    "Each change in parameters required editing the code and re-running it, which is inefficient when you want to test multiple settings or process multiple images.\n",
    "\n",
    "Now we’ll make our work **smarter and faster** by introducing two types of automation:\n",
    "\n",
    "1. **Parameter Sweep:**  \n",
    "   Applying *different settings* (e.g., filter size, threshold method) to the **same image**, so we can compare their effects.\n",
    "\n",
    "2. **Batch Processing:**  \n",
    "   Applying *final workflow* to **many images**, so we can process entire datasets automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba78f3a",
   "metadata": {},
   "source": [
    "---\n",
    "##### Parameter Sweep Example\n",
    "\n",
    "Let’s compare how different levels of Gaussian blur affect the same image.\n",
    "\n",
    "- We define a list of parameter values (sigma_values) to test.\n",
    "- We use a simple **loop** to apply the same function with each parameter.\n",
    "- We use another **loop** to plot images with subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42197a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one image\n",
    "input_image = iio.imread('../data/noisy_cells.tif')\n",
    "\n",
    "# Define sigma values for Gaussian blur\n",
    "sigma_values = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "# Apply Gaussian filter with different sigmas\n",
    "blurred_images = []\n",
    "for sigma in sigma_values:\n",
    "    blurred = filters.gaussian(input_image, sigma=sigma)\n",
    "    blurred_images.append(blurred)\n",
    "\n",
    "# Alternative: list comprehension\n",
    "# blurred_images = [filters.gaussian(image, sigma=s) for s in sigma_values]\n",
    "\n",
    "# Plot results side by side\n",
    "fig, axes = plt.subplots(1, len(sigma_values), figsize=(25, 5))\n",
    "\n",
    "# zip() is a built-in Python function \n",
    "# it lets you iterate over multiple sequences (lists, tuples...) in parallel\n",
    "for ax, s, img in zip(axes, sigma_values, blurred_images):\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(f\"σ = {s}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Effect of Gaussian Blur with Different σ\", fontsize=16)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7fc485",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** ---\n",
    "\n",
    "Test how different thresholding algorithms segment the same image.\n",
    "\n",
    "- Use the image from previous exercise (input_image).\n",
    "- Create a dictionary of thresholding methods (Otsu, Li, Yen, Minimum).\n",
    "    - such as `dict = {'name1': function1(), 'name2': function2()}`\n",
    "- Create a new empty dictionary to store results,\n",
    "- Use a loop to iterate over the methods in dictionary\n",
    "    - apply thresholding method to get threshold value\n",
    "    - generate a binary mask with threshold value\n",
    "    - store binary array in the new dictionary under the method name\n",
    "- Plot the original image alongside binary arrays in one figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a8b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbc158b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "from skimage.filters import threshold_otsu, threshold_li, threshold_yen, threshold_minimum\n",
    "\n",
    "# Dictionary of thresholding methods\n",
    "methods = {\n",
    "    \"Otsu\": threshold_otsu,\n",
    "    \"Li\": threshold_li,\n",
    "    \"Yen\": threshold_yen,\n",
    "    \"Min\": threshold_minimum\n",
    "}\n",
    "\n",
    "# Create empty dictionary to store masks\n",
    "masks = {}\n",
    "\n",
    "# Apply each thresholding method in a loop\n",
    "for name, func in methods.items():\n",
    "    thresh = func(input_image)        \n",
    "    mask = input_image > thresh      \n",
    "    masks[name] = mask          \n",
    "\n",
    "# Add original image to the new dictionary to make plotting easier\n",
    "masks['raw'] = input_image\n",
    "\n",
    "# Plot original image + threshold results\n",
    "fig, axes = plt.subplots(1, len(masks), figsize=(16, 5))\n",
    "\n",
    "for ax, (name, mask) in zip(axes, masks.items()):\n",
    "    ax.imshow(mask, cmap=\"gray\")\n",
    "    ax.set_title(name)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166aea06",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d086874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By the way, skimage has a function to try all thresholds\n",
    "\n",
    "filters.try_all_threshold(input_image, figsize=(8, 5), verbose=False)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f2aded",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### Automated workflow\n",
    "\n",
    "\n",
    "Now, we will apply a complete workflow automatically, from image → segmentation → measurements → results table.\n",
    "\n",
    "We will simply take the indivudual steps and package them into a function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build full workflow - from image to table\n",
    "\n",
    "def analyze_slice(image_array, slice_index = 0):\n",
    "    filtered_array = filters.gaussian(image_array, 3)\n",
    "    threshold_value = filters.threshold_otsu(filtered_array)\n",
    "    mask = filtered_array > threshold_value\n",
    "    processed_mask = ndi.binary_fill_holes(mask)\n",
    "    mask_cleaned = morphology.remove_small_objects(processed_mask, min_size=100) \n",
    "    label_image = measure.label(mask_cleaned)\n",
    "    props_dict = measure.regionprops_table(label_image, intensity_image=image_array,\n",
    "                                           properties=('label', 'area', 'mean_intensity'))\n",
    "    \n",
    "    results_df = pd.DataFrame(props_dict)\n",
    "    # Add the source filename to track our data\n",
    "    results_df['slice'] = slice_index\n",
    "    return results_df, label_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51123c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will run our function on single slice and validate results\n",
    "\n",
    "image_3d = iio.imread('../data/nuclei_stack1.tif')\n",
    "\n",
    "print(image_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7585643",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_slice = image_3d[10,:,:]\n",
    "\n",
    "my_results, my_label = analyze_slice(input_slice, 10)\n",
    "\n",
    "my_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eeb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(my_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c11bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use our function in a loop to easily process all slices\n",
    "\n",
    "# get number of slices in our image\n",
    "n_slices = image_3d.shape[0]\n",
    "\n",
    "# initialize empty variables for storage of outputs\n",
    "new_df = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "# run loop\n",
    "for index in range(n_slices):\n",
    "    # Print progress\n",
    "    print('Processing slice:', index)\n",
    "\n",
    "    # Analyze one slice\n",
    "    result_df, result_labels = analyze_slice(image_3d[index], index)\n",
    "    \n",
    "    # Append results to DataFrame\n",
    "    new_df = pd.concat([new_df, result_df], ignore_index=True)\n",
    "    \n",
    "    # Store labels for visualization or later use\n",
    "    labels.append(result_labels)\n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0401296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_stack = np.stack(labels)\n",
    "stackview.slice(labels_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421de31",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** --- \n",
    "\n",
    "**Create an Analysis Function** - Follow the steps below to build a new function. \n",
    "\n",
    "**Instructions:**\n",
    "1. Define a function called `analyze_nuclei`.\n",
    "2. This function should take two arguments: `image_array` (the image to process) and `source` (a string of file name).\n",
    "3. Inside the function, perform the entire pipeline defined below (blur, threshold, clean, label).\n",
    "4. After labeling, use `measure.regionprops_table` to calculate the `'label'`, `'area'`, and `'mean_intensity'` for each nucleus. Remember to use the original `image_array` for the `intensity_image`.\n",
    "5. Convert the resulting dictionary to a Pandas DataFrame.\n",
    "6. Add a new column to the DataFrame called `'filename'` and set its value to the `source` argument.\n",
    "7. The function should `return` this final DataFrame and labels.\n",
    "8. Test your function by calling it with the provided image and filename. \n",
    "9. Print the head of the resulting DataFrame and show resulting segmentation to check that it works.\n",
    "\n",
    "```python\n",
    "# processing pipeline\n",
    "filtered_image = filters.gaussian(image, 1)\n",
    "threshold_value = filters.threshold_otsu(filtered_image)\n",
    "mask = filtered_image > threshold_value\n",
    "processed_mask = ndi.binary_fill_holes(mask)\n",
    "mask_cleaned = morphology.remove_small_objects(processed_mask, min_size=50) \n",
    "label_image = measure.label(mask_cleaned)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = iio.imread('../data/batch_analysis/i0.tif')\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9aa763",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "# Create function\n",
    "def analyze_nuclei(image_array, source):\n",
    "    filtered_array = filters.gaussian(image_array, sigma=1)\n",
    "    threshold_value = filters.threshold_otsu(filtered_array)\n",
    "    mask = filtered_array > threshold_value\n",
    "    processed_mask = ndi.binary_fill_holes(mask)\n",
    "    mask_cleaned = morphology.remove_small_objects(processed_mask, min_size=50)\n",
    "    label_image = measure.label(mask_cleaned)\n",
    "\n",
    "    props = measure.regionprops_table(label_image, intensity_image=image_array,\n",
    "                                      properties=['label', 'area', 'mean_intensity'])\n",
    "    df = pd.DataFrame(props)\n",
    "\n",
    "    df['filename'] = source\n",
    "\n",
    "    return df, label_image\n",
    "\n",
    "\n",
    "# Call the analysis function\n",
    "results_df, labels = analyze_nuclei(test_image, source='i0.tif')\n",
    "\n",
    "# Show first rows of results\n",
    "print(results_df.head())\n",
    "\n",
    "# Show segmentation\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(labels, cmap='nipy_spectral')\n",
    "plt.title(\"Labeled Nuclei\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Optional: blend with original image using stackview\n",
    "stackview.blend(test_image, labels)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb436bf",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### A Quick Guide to File Paths\n",
    "\n",
    "Packages: `os`, `glob`, and `pathlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fdd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- `os.path.join()`: The safe way to build paths ---\n",
    "import os\n",
    "# This automatically uses the correct separator for your OS (`/` or `\\`)\n",
    "folder = \"my_data\"\n",
    "filename = \"image_01.tif\"\n",
    "# This is the RIGHT way to do it:\n",
    "correct_path = os.path.join(folder, \"subfolder\", filename)\n",
    "print(f\"OS-safe path: {correct_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514989a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- `glob.glob()`: The way to find files with wildcards ---\n",
    "import glob\n",
    "\n",
    "# Find all files ending in .tif\n",
    "tif_files = glob.glob(os.path.join(\"../images\", \"*.tif\"))\n",
    "print(f\"\\nFound TIF files: {tif_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6053352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- `pathlib`  ---\n",
    "from pathlib import Path\n",
    "\n",
    "# It uses objects and the `/` operator, which is very clean.\n",
    "p = Path(\"my_data\")\n",
    "csv_file_path = p / \"summary.csv\"\n",
    "print(f\"\\nPathlib object: {csv_file_path}\")\n",
    "print(f\"Does this file exist? {csv_file_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd93fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images in folder\n",
    "\n",
    "# lets combine our previous exercises together\n",
    "# use for-loop to apply function on all images in folder \n",
    "\n",
    "# Step 1: Define our final, reusable analysis function (using Otsu)\n",
    "def analyze_image_final(image_array, source_filename):\n",
    "    blurred_image = filters.gaussian(image_array, 3)\n",
    "    threshold_value = filters.threshold_otsu(blurred_image)\n",
    "    mask = blurred_image > threshold_value\n",
    "    label_image = measure.label(mask)\n",
    "    props_dict = measure.regionprops_table(label_image, intensity_image=image_array,\n",
    "                                           properties=('label', 'area', 'mean_intensity'))\n",
    "    results_df = pd.DataFrame(props_dict)\n",
    "    # Add the source filename to track our data\n",
    "    results_df['source_file'] = source_filename\n",
    "\n",
    "    return results_df\n",
    "\n",
    "# Step 2: Find the files\n",
    "input_folder = \"../data/batch_analysis/input\"\n",
    "file_list = glob.glob(os.path.join(input_folder, \"*.png\"))\n",
    "\n",
    "# Step 3: Loop and aggregate results\n",
    "all_image_results = []\n",
    "print(\"\\nStarting batch processing...\")\n",
    "\n",
    "for file_path in file_list:\n",
    "    print(f\"Processing: {file_path}\")\n",
    "    image = iio.imread(file_path)\n",
    "    # Get just the filename from the full path for cleaner tables\n",
    "    filename_only = os.path.basename(file_path)\n",
    "    \n",
    "    single_image_df = analyze_image_final(image, filename_only)\n",
    "    all_image_results.append(single_image_df)\n",
    "    \n",
    "# Step 4: Concatenate into a final DataFrame\n",
    "final_batch_df = pd.concat(all_image_results, ignore_index=True)\n",
    "\n",
    "print(\"\\n--- Final Batch Results ---\")\n",
    "final_batch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f89f54",
   "metadata": {},
   "source": [
    "##### --- ***Exercise*** --- \n",
    "\n",
    "***Batch Process the Entire Dataset***\n",
    "\n",
    "You have the tools, you have the function. Now it's time to automate everything!\n",
    "\n",
    "**Instructions:**\n",
    "1. Use `glob` to get a list of all `.tif` files in the `batch_analysis/nuclei_data` folder.\n",
    "2. Create an empty list called `all_nuclei_results`.\n",
    "3. Write a `for` loop that iterates through your list of file paths.\n",
    "4. Inside the loop:\n",
    "    - Load the current image using `iio.imread()`.\n",
    "    - Get just the filename (without the folder path) using `os.path.basename()`.\n",
    "    - Call your `analyze_nuclei` function with the loaded image and the filename.\n",
    "    - Append the DataFrame returned by the function to your `all_nuclei_results` list.\n",
    "5. After the loop, use `pd.concat()` to combine the list of DataFrames into a single, master DataFrame.\n",
    "6. Print the head and tail of your final DataFrame to see the combined results from all images.\n",
    "7. As a final analysis, create a boxplot showing the distribution of nuclei `area` for each of the source images.\n",
    "    - What happened between 5th and 6th frames? \n",
    "    - *Hint*: `seaborn.boxplot` is great for this, you can use `source` column as `hue` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ef074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376df0c3",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see the example solution</summary>\n",
    "\n",
    "```python\n",
    "# 1. Get list of all .tif files in the folder\n",
    "image_files = glob.glob(\"../data/batch_analysis/nuclei_data/*.tif\")\n",
    "\n",
    "# 2. Create an empty list to store results\n",
    "all_nuclei_results = []\n",
    "\n",
    "# 3. Loop through each file\n",
    "for file_path in image_files:\n",
    "    # Load image\n",
    "    image_array = iio.imread(file_path)\n",
    "    \n",
    "    # Extract filename only\n",
    "    filename = os.path.basename(file_path)\n",
    "    \n",
    "    # Analyze nuclei\n",
    "    df, labels = analyze_nuclei(image_array, filename)\n",
    "    \n",
    "    # Append results to list\n",
    "    all_nuclei_results.append(df)\n",
    "\n",
    "# 5. Combine all DataFrames into a single master DataFrame\n",
    "master_df = pd.concat(all_nuclei_results, ignore_index=True)\n",
    "\n",
    "# 6. Inspect results\n",
    "print(master_df.head())\n",
    "print(master_df.tail())\n",
    "\n",
    "# 7. Boxplot of nuclei area per image\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=master_df, x='filename', y='area', palette=\"Set3\", hue='filename')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"Nuclei Area\")\n",
    "plt.xlabel(\"Source Image\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9558e98d",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "#### Slice-by slice reading\n",
    "\n",
    "When working with image data stored as a series of files, it’s often useful to load all slices into a single multidimensional array for easier processing.\n",
    "\n",
    "The **scikit-image** function `imread_collection()` allows you to read multiple images at once using a filename pattern.\n",
    "You can use a wildcard (*) to match all files in a folder that belong to your dataset. This collection can then be converted into a **NumPy** array, effectively creating an image stack.\n",
    "\n",
    "However, the number of z-slices, channels or frames is not recognized. You have to reshape the loaded data into the appropriate multidimensional form (for example, (z, c, y, x)) your self.\n",
    "\n",
    "*Note*: Alternatively, you can build your own for-loops to load images from disk manually.\n",
    "This approach gives you more flexibility — for example, to sort slices and channels, skip specific files, or arrange the data into custom dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "im_collection = io.imread_collection('../data/batch_analysis/tiffs/' + \"*\")\n",
    "image_stack = im_collection.concatenate()\n",
    "image_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 2\n",
    "num_z_slices = 5\n",
    "num_t_frames = 10\n",
    "image5d = np.reshape(image_stack, (num_t_frames, num_z_slices, num_channels, image_stack.shape[-2], image_stack.shape[-1]))\n",
    "image5d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackview.slice(image5d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "papi-intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
